<p align = "center" draggable=â€falseâ€ ><img src="https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719" 
     width="200px"
     height="auto"/>
</p>

## <h1 align="center" id="heading">Session 9: Fine-tuning Embeddings</h1>

| ğŸ¤“ Pre-work | ğŸ“° Session Sheet | âºï¸ Recording     | ğŸ–¼ï¸ Slides        | ğŸ‘¨â€ğŸ’» Repo         | ğŸ“ Homework      | ğŸ“ Feedback       |
|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|
| [Session 9: Pre-Work](https://www.notion.so/Session-9-Fine-Tuning-Embeddings-or-Domain-Adapted-Retrieval-189cd547af3d80e2a20af073060f2c0c?pvs=4#189cd547af3d81048f71c349e2c5ca9d)| [Session 9: Fine-Tuning Embeddings or Domain-Adapted Retrieval](https://www.notion.so/Session-9-Fine-Tuning-Embeddings-or-Domain-Adapted-Retrieval-189cd547af3d80e2a20af073060f2c0c) | [Recording](https://us02web.zoom.us/rec/share/eWW79xYKT51-L-EWPAYEOabirkPjAuV_oyPb-7PeOPc-tdZnIZmv817wdesULUkw.dIVe86Fsaidc0M5h) (9P.Y.Ikv) | [Session 9: Fine-Tuning Embeddings or Domain-Adapted Retrieval](https://www.canva.com/design/DAGe090dCmE/mCfN3RdVz9StXX6ec9U_kg/edit?utm_content=DAGe090dCmE&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)|You Are Here! | [Session 9 Assignment: Fine-Tuning Embeddings or Domain-Adapted Retrieval](https://forms.gle/eYVTYBLdDsV5QK1j8) | [AIE5 Feedback 2/11](https://forms.gle/FgtkahAXGivuZWsV8) |

In today's assignment, we'll be fine-tuning embeddings!

- ğŸ¤ Breakout Room #1:
  - Task 1: Dependencies and Boilerplate
  - Task 2: Loading Data
  - Task 3: Constructing a Fine-tuning Dataset
  - Task 4: Fine-tuning `snowflake-arctic-embed-l`
  - Task 5: Evaluating our Retriever
    
The notebook Colab link is located [here](https://colab.research.google.com/drive/1tNc1uzPE1tgjswmLLuYczOZtxCw1Ifac?usp=sharing)

## Ship ğŸš¢

The completed notebook!

#### ğŸ—ï¸ BONUS ACTIVITY (FULL MARKS IF COMPLETED IN LIEU OF ABOVE NOTEBOOK):

Using your own source data (from multiple sources) fine-tune an embedding model by synthetically generating 100 question/context using the Ragas Knowledge Graph Approach.

Compare and contrast this model to a model fine-tuned using the naive approach found in the notebook. 

> NOTE: You can use any embedding model and fine-tuning framework that you desire!

### Deliverables

- A short Loom of the notebook, and a 1min. walkthrough of the application in full

## Share ğŸš€

Make a social media post about your final application!

### Deliverables

- Make a post on any social media platform about what you built!

Here's a template to get you started:

```
ğŸš€ Exciting News! ğŸš€

I am thrilled to announce that I have just built and shipped fine-tuning embeddings! ğŸ‰ğŸ¤–

ğŸ” Three Key Takeaways:
1ï¸âƒ£ 
2ï¸âƒ£ 
3ï¸âƒ£ 

Let's continue pushing the boundaries of what's possible in the world of AI and question-answering. Here's to many more innovations! ğŸš€
Shout out to @AIMakerspace !

#LangChain #QuestionAnswering #RetrievalAugmented #Innovation #AI #TechMilestone

Feel free to reach out if you're curious or would like to collaborate on similar projects! ğŸ¤ğŸ”¥
```